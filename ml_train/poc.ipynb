{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\n",
    "    host='localhost',\n",
    "    database='db',\n",
    "    user='postgres',\n",
    "    password='postgres'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"SELECT version()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_version = cur.fetchone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(db_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stock_code_sql = \"\"\"\n",
    "    SELECT stock.stock_code\n",
    "    FROM stock\n",
    "    ORDER BY stock.stock_code;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(all_stock_code_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res)\n",
    "stock_codes = [x[0] for x in res]\n",
    "print(stock_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_history_sql = \"\"\"\n",
    "    SELECT history.date, history.close, history.stock_code\n",
    "    FROM history\n",
    "    ORDER BY history.stock_code, history.date;\n",
    "\"\"\"\n",
    "# cur.execute(select_history_sql)\n",
    "# res = cur.fetchall()\n",
    "# print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in res[0]:\n",
    "#     print(x, type(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in res:\n",
    "#     print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_series(time, series, label, start=0, end=None, format=\"-\"):\n",
    "    plt.plot(time[start:end], series[start:end], format, label=label)\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Value\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p_sql = \"\"\"\n",
    "#     SELECT * FROM get_stock_history('%s');\n",
    "# \"\"\" % (\"0050\")\n",
    "# df = pd.read_sql(p_sql, con=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepared_sql = \"\"\"\n",
    "#     PREPARE get_history AS\n",
    "#     SELECT h.date, h.close, h.stock_code\n",
    "#     FROM history as h\n",
    "#     WHERE h.stock_code = $1;\n",
    "# \"\"\"\n",
    "# cur.execute(prepared_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_p_sql = \"\"\"\n",
    "    SELECT h.date, h.close, h.high, h.low, h.open, h.capacity, h.turnover, h.transactions, h.stock_code\n",
    "    FROM history as h\n",
    "    WHERE h.stock_code = %(stock_code)s;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(para_p_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cur.execute(p_sql)\n",
    "# res = cur.fetchall()\n",
    "# print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_sql(para_p_sql, con=conn, params={'stock_code': '006208'})\n",
    "df = pd.read_sql(para_p_sql, con=conn, params={'stock_code': '0050'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mae: 2.2646\n",
    "# matrix = df[['close', 'high', 'low', 'open', 'capacity', 'turnover', 'transactions']].values\n",
    "matrix = df[['close']].values\n",
    "time = df['date'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix[:9, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_series(time, matrix[:, 0], 'lr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 20\n",
    "batch_size = 32\n",
    "# split_time = 150  # 500\n",
    "\n",
    "ratio = 0.8\n",
    "train_idx = int(matrix.shape[0] * ratio)\n",
    "val_idx = (matrix.shape[0] - train_idx) // 2 + train_idx\n",
    "\n",
    "shuffle_buffer = 1000\n",
    "dim = matrix.shape[1]\n",
    "\n",
    "def windowed_dataset_m(matrix, window_size=20, batch_size=32, shuffle_buffer=1000):\n",
    "#     matrix = tf.expand_dims(matrix, axis=-1)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(matrix)\n",
    "    dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)\n",
    "    dataset = dataset.flat_map(lambda window: window.batch(window_size + 1))\n",
    "    dataset = dataset.shuffle(shuffle_buffer)\n",
    "    dataset = dataset.map(lambda window: (window[:-1], [window[-1:][0][0]]))\n",
    "    dataset = dataset.batch(batch_size).prefetch(1)\n",
    "    return dataset\n",
    "\n",
    "def model_predict_m(model, matrix, window_size=20):\n",
    "    ds = tf.data.Dataset.from_tensor_slices(matrix)\n",
    "    ds = ds.window(window_size, shift=1, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda window: window.batch(window_size))\n",
    "    ds = ds.batch(32).prefetch(1)\n",
    "    forecast = model.predict(ds)\n",
    "    return forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training set\n",
    "time_train = time[:train_idx]\n",
    "x_train = matrix[:train_idx]\n",
    "\n",
    "# validation set\n",
    "time_valid = time[train_idx:val_idx]\n",
    "x_val = matrix[train_idx:val_idx]\n",
    "\n",
    "# test set\n",
    "time_test = time[val_idx:]\n",
    "x_test = matrix[val_idx:]\n",
    "\n",
    "print(matrix.shape)\n",
    "print(time_train.shape, time_valid.shape, time_test.shape)\n",
    "print(x_train.shape, x_val.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = windowed_dataset_m(x_train, window_size, shuffle_buffer)\n",
    "valid_ds = windowed_dataset_m(x_val, window_size, shuffle_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for window in train_ds:\n",
    "# #     for val in window:\n",
    "# #         print(val.numpy())\n",
    "#     x, y = window\n",
    "#     print(x.shape, y.shape)\n",
    "#     print(x.numpy())\n",
    "#     print('-')\n",
    "#     print(y.numpy())\n",
    "\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment on Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_model_1d(window_size, dim):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv1D(filters=8,\n",
    "                               kernel_size=5,\n",
    "                               strides=1,\n",
    "                               padding=\"causal\",\n",
    "                               activation=\"relu\",\n",
    "                               input_shape=[window_size, dim]),\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16, return_sequences=True)),\n",
    "#         tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
    "#         tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "#         tf.keras.layers.LSTM(64, return_sequences=True),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(20, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(10, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def raw_model_2d(window_size, dim):\n",
    "#     model = tf.keras.models.Sequential([\n",
    "#         tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1), input_shape=[window_size, dim]),\n",
    "#         tf.keras.layers.Conv2D(filters=64,\n",
    "#                                kernel_size=(5, dim),\n",
    "#                                strides=1,\n",
    "#                                activation=\"relu\"),\n",
    "# #         tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
    "# #         tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
    "# # #         tf.keras.layers.LSTM(64, return_sequences=True),\n",
    "# #         tf.keras.layers.Flatten(),\n",
    "# #         tf.keras.layers.Dense(30, activation=\"relu\"),\n",
    "# #         tf.keras.layers.Dense(10, activation=\"relu\"),\n",
    "# #         tf.keras.layers.Dense(1),\n",
    "        \n",
    "#     ])\n",
    "#     return model\n",
    "\n",
    "# model = raw_model_2d(window_size, dim)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = raw_model_1d(window_size, dim)\n",
    "\n",
    "lr_schedule = tf.keras.callbacks.LearningRateScheduler(\n",
    "    lambda epoch: 1e-8 * 10**(epoch / 20))\n",
    "\n",
    "# optimizer = tf.keras.optimizers.SGD(lr=1e-8, momentum=0.9)\n",
    "optimizer = tf.keras.optimizers.Adam(lr=1e-8)\n",
    "model.compile(loss=tf.keras.losses.Huber(),\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"mae\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_ds, epochs=200, callbacks=[lr_schedule])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogx(history.history[\"lr\"], history.history[\"loss\"])\n",
    "plt.axis([1e-8, 10, 0, 60])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = raw_model_1d(window_size, dim)\n",
    "\n",
    "# optimizer = tf.keras.optimizers.SGD(lr=1e-3, momentum=0.9)\n",
    "optimizer = tf.keras.optimizers.Adam(lr=1e-3)\n",
    "model.compile(loss=tf.keras.losses.Huber(),\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"mae\"])\n",
    "model.summary()\n",
    "\n",
    "checkpoint_filepath = './tmp/checkpoint'\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_mae', patience=50)\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_mae',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "history = model.fit(train_ds,\n",
    "                    validation_data=valid_ds,\n",
    "                    callbacks=[early_stop, model_checkpoint],\n",
    "                    verbose=2,\n",
    "                    epochs=500)\n",
    "\n",
    "model.load_weights(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = model_predict_m(model, matrix, window_size)\n",
    "# remove the latest one prediction (prediction in the future; we don't know the answer, so strip it now)\n",
    "forecast = forecast[:-1]\n",
    "print(forecast.shape)\n",
    "print(matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### show test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_test = forecast[val_idx - window_size:]\n",
    "if len(matrix.shape) > 1:\n",
    "    x_test_close = x_test[:, 0]\n",
    "else:\n",
    "    x_test_close = x_test\n",
    "print(forecast_test.shape)\n",
    "print(x_test_close.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = tf.keras.metrics.MeanAbsoluteError()\n",
    "m.update_state(x_test_close, forecast_test)\n",
    "m.result().numpy()\n",
    "# tf.keras.metrics.mean_absolute_error(x_val, forecast_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"mean absolute error:\", m.result().numpy())\n",
    "plt.figure(figsize=(10, 6))\n",
    "plot_series(time_test, x_test_close, 'true')\n",
    "plot_series(time_test, forecast_test, 'predict')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### show valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forecast_valid = forecast[split_time - window_size:-1, -1, 0]\n",
    "\n",
    "forecast_valid = forecast[train_idx - window_size:val_idx - window_size]\n",
    "if len(matrix.shape) > 1:\n",
    "    x_val_close = x_val[:, 0]\n",
    "else:\n",
    "    x_val_close = x_val\n",
    "print(forecast_valid.shape)\n",
    "print(x_val_close.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_val_close[:2])\n",
    "print(forecast_valid[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = tf.keras.metrics.MeanAbsoluteError()\n",
    "m.update_state(x_val_close, forecast_valid)\n",
    "m.result().numpy()\n",
    "# tf.keras.metrics.mean_absolute_error(x_val, forecast_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"mean absolute error:\", m.result().numpy())\n",
    "plt.figure(figsize=(10, 6))\n",
    "plot_series(time_valid, x_val_close, 'true')\n",
    "plot_series(time_valid, forecast_valid, 'predict')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### show train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forecast_valid = forecast[split_time - window_size:-1, -1, 0]\n",
    "forecast_train = forecast[:train_idx]\n",
    "if len(matrix.shape) > 1:\n",
    "    x_train_close = x_train[:, 0]\n",
    "else:\n",
    "    x_train_close = x_train\n",
    "print(time_train.shape)\n",
    "print(forecast_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plot_series(time_train, x_train_close, 'true')\n",
    "\n",
    "# time: [0, window_size]\n",
    "# forecast_train: [window_size, split_time + window_size] \n",
    "# to display train set in the same figure, strip forecast_train[split_time:split_time+window_size]\n",
    "\n",
    "plot_series(time_train[window_size:], forecast_train[:-window_size], 'predict')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"output layers\", [o.name[:-2] for o in model.outputs])\n",
    "print(\"input layers\", [i.name[:-2] for i in model.inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.python import saved_model\n",
    "# from tensorflow.python.saved_model.signature_def_utils_impl import build_signature_def, predict_signature_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_dir = os.getcwd()\n",
    "# # print(curr_dir)\n",
    "# export_dir = os.path.join(curr_dir, \"stocknet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# builder = saved_model.builder.SavedModelBuilder(export_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_version = 1\n",
    "# signature = predict_signature_def(\n",
    "#     inputs={\"input\": model.input},\n",
    "#     outputs={\"output\": model.output}\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "curr_dir = os.getcwd()\n",
    "print(curr_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version = 1\n",
    "model_save_path = os.path.join(curr_dir, \"stocknet/{:d}/\".format(model_version))\n",
    "tf.saved_model.save(model, model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
